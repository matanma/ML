{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip3 install -U -q ipywidgets\n",
    "# !pip3 install -U -q pyarrow\n",
    "# !jupyter nbextension enable --py widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Standard Data Science Helpers\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import random \n",
    "\n",
    "from sklearn.datasets import make_classification, make_blobs\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import cufflinks as cf\n",
    "cf.go_offline(connected=True)\n",
    "cf.set_config_file(colorscale='plotly', world_readable=True)\n",
    "\n",
    "# Extra options\n",
    "pd.options.display.max_rows = 30\n",
    "pd.options.display.max_columns = 25\n",
    "\n",
    "# Show all code cells outputs\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "import os\n",
    "from IPython.display import Image, display, HTML\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "from sklearn.base import clone\n",
    " \n",
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some utility functions.\n",
    "\n",
    "class DataContainer():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def set_x(self, X):\n",
    "        self.X = X\n",
    "    \n",
    "    def set_y(self, y):\n",
    "        self.y = y\n",
    "        \n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "    \n",
    "def classification_assessment(X_test, y_test, y_test_predicted, clf):\n",
    "    print(classification_report(y_test, y_test_predicted))\n",
    "    cnf_matrix = confusion_matrix(y_test, y_test_predicted, labels=[1,0])\n",
    "    np.set_printoptions(precision=2)\n",
    "\n",
    "    # Plot non-normalized confusion matrix\n",
    "    plt.figure()\n",
    "    plot_confusion_matrix(cnf_matrix, classes=['incident=1','no incident=0'],normalize= False,  title='Confusion matrix')\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "\n",
    "    # plot ROC\n",
    "    plt.figure()\n",
    "    lr_probs = clf.predict_proba(X_test)\n",
    "    # keep probabilities for the positive outcome only\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    # calculate scores\n",
    "    ns_auc = roc_auc_score(y_test, ns_probs)\n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "    # summarize scores\n",
    "    print('No Skill: ROC AUC=%.3f' % (ns_auc))\n",
    "    print('Logistic: ROC AUC=%.3f' % (lr_auc))\n",
    "    # calculate roc curves\n",
    "    ns_fpr, ns_tpr, ns_thresh = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, lr_thresh = roc_curve(y_test, lr_probs)\n",
    "    # plot the roc curve for the model\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle='--', label='No Skill')\n",
    "    plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "    # axis labels\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    # show the legend\n",
    "    plt.legend()\n",
    "    # show the plot\n",
    "    plt.show()\n",
    "\n",
    "    return lr_probs\n",
    "    \n",
    "    \n",
    "def dilute_class(X, y, class_tag, dilute_factor):\n",
    "    y_indices = y==class_tag\n",
    "    num_class_entries = sum(y_indices)\n",
    "    diluted_ys_indices =  random.sample(range(num_class_entries), int(num_class_entries*dilute_factor))\n",
    "    diluted_ys = y[y_indices][diluted_ys_indices]\n",
    "    diluted_X_other_classes = X[~y_indices]\n",
    "    diluted_X_class = X[y_indices][diluted_ys_indices]\n",
    "    diluted_X = np.concatenate([diluted_X_other_classes, diluted_X_class])\n",
    "    diluted_y = np.concatenate([ y[~y_indices], diluted_ys])\n",
    "    \n",
    "    return diluted_X, diluted_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b92952800f9d415c802972db0b431474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='num_samples', options=(10000, 500000, 1000000), value=10000), Floaâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#See https://plotly.com/python/histograms/\n",
    "\n",
    "%matplotlib qt\n",
    "\n",
    "data_container = DataContainer()\n",
    "from ipywidgets import interact, widgets\n",
    "# correlations(column1=list(df.select_dtypes('number').columns), \n",
    "#                  column2=list(df.select_dtypes('number').columns)):\n",
    "\n",
    "@interact_manual\n",
    "def choose_dataset( num_samples=[10000, 500000, 1000000], \n",
    "                    center_zero=widgets.FloatSlider(min=-2,max=-0.5,step=0.1,value=-1),\n",
    "                    center_one=widgets.FloatSlider(min=0.5,max=2,step=0.1,value=1),\n",
    "                    std_zero=widgets.FloatSlider(min=0.2,max=2,step=0.1,value=0.8),\n",
    "                    std_one=widgets.FloatSlider(min=0.2,max=2,step=0.1,value=0.5)\n",
    "                  ):\n",
    "    display(HTML(f'<h2>Plotting dataset of size {num_samples} <h2>'))\n",
    "    dataset_artificial_balanced_1_feature = \\\n",
    "                            make_blobs(n_samples=num_samples, n_features=1, centers=[[center_zero], [center_one]],\n",
    "                                cluster_std=[std_zero, std_one],  shuffle=False, random_state=4) \n",
    "    X, y = dataset_artificial_balanced_1_feature\n",
    "    X = X\n",
    "    data_container.set_x(X)\n",
    "    data_container.set_y(y)\n",
    "    X_ones = X[y==1].T[0]\n",
    "    X_zeros = X[y==0].T[0]\n",
    "    print(\"1: mean: {:0.3f}, std: {:0.3f} \\n0: mean: {:0.3f}, std: {:0.3f} \".format(X_ones.mean(), X_ones.std(), X_zeros.mean(), X_zeros.std()))\n",
    " \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=X_ones, nbinsx=500, histnorm='probability density', opacity=0.7, name='ones'))\n",
    "    fig.add_trace(go.Histogram(x=X_zeros, nbinsx=500, histnorm='probability density', opacity=0.7, name='zeros'))\n",
    "    fig.show()\n",
    "\n",
    "#     fig, ax_hist = plt.subplots()\n",
    "#     ax_hist.hist(X_ones, bins = 500, density=True, alpha = 0.7, label=\"ones\")\n",
    "#     ax_hist.hist(X_zeros, bins = 500, density=True, alpha = 0.7, label = \"zeros\")\n",
    "#     ax_hist.legend()\n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, \"Classifier's probabilities over test set\")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'x')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'prob(y(x)=1)')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib qt\n",
    "probs_fig, probs_axs = plt.subplots(2,1)\n",
    "data_container.probs_ax, data_container.x_ax = probs_axs\n",
    "data_container.probs_ax.set_title(\"Classifier's probabilities over test set\")\n",
    "data_container.probs_ax.set_xlabel(\"x\")\n",
    "data_container.probs_ax.set_ylabel(\"prob(y(x)=1)\")\n",
    "\n",
    "data_container.probs_fig = probs_fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Now, let's apply a standard classification and assess the results.</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      1007\n",
      "           1       0.92      0.96      0.94       993\n",
      "\n",
      "    accuracy                           0.94      2000\n",
      "   macro avg       0.94      0.94      0.94      2000\n",
      "weighted avg       0.94      0.94      0.94      2000\n",
      "\n",
      "Confusion matrix, without normalization\n",
      "[[955  38]\n",
      " [ 81 926]]\n",
      "No Skill: ROC AUC=0.500\n",
      "Logistic: ROC AUC=0.983\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x1323eaf50>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %matplotlib inline\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_container.X, data_container.y, test_size=0.2)\n",
    "clf_lr = LogisticRegressionCV(cv=5, random_state=4).fit(X_train, y_train)\n",
    "y_hat_lr = clf_lr.predict(X_test)\n",
    "prediction_probs = classification_assessment(X_test, y_test, y_hat_lr, clf_lr)\n",
    "# %matplotlib qt\n",
    "data_container.probs_ax.scatter(X_test, prediction_probs)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Next, we're going to dilute the '1' class to obtain an imbalanced dataset </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59d90ea52e6414cb86b80fc505bf68d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.01, description='dilute_factor', max=1.0, min=0.01, step=0.01), Buttâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "@interact_manual\n",
    "def dilute_ones( dilute_factor=widgets.FloatSlider(min=0.01,max=1,step=0.01,value=0.01)):\n",
    "    X = data_container.X\n",
    "    y = data_container.y\n",
    "    #Dilute the 1's class\n",
    "#     ones_y_indices = y==1\n",
    "#     num_ones = sum(ones_y_indices)\n",
    "#     diluted_ys_indices =  random.sample(range(num_ones), int(num_ones*dilute_factor))\n",
    "#     diluted_ys = y[ones_y_indices][diluted_ys_indices]\n",
    "#     diluted_X_zeros = X[y==0]\n",
    "#     diluted_X_ones = X[ones_y_indices][diluted_ys_indices]\n",
    "#     diluted_X = np.concatenate([diluted_X_zeros, diluted_X_ones])\n",
    "#     diluted_y = np.concatenate([ y[y==0], diluted_ys])\n",
    "    diluted_X, diluted_y = dilute_class(X, y, 1, dilute_factor)\n",
    "    data_container.diluted_X = diluted_X\n",
    "    data_container.diluted_y = diluted_y\n",
    "    diluted_X_zeros = diluted_X[diluted_y == 0]\n",
    "    diluted_X_ones = diluted_X[diluted_y == 1]\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=diluted_X_zeros.T[0], nbinsx=1000))\n",
    "    fig.add_trace(go.Histogram(x=diluted_X_ones.T[0], nbinsx=1000))\n",
    "    fig.show()\n",
    "    \n",
    "    data_container.x_ax.hist(diluted_X_zeros.T[0], bins=1000)\n",
    "    data_container.x_ax.hist(diluted_X_ones.T[0], bins=1000)\n",
    "    \n",
    "#     fig.show()\n",
    "#     plt.figure()\n",
    "#     plt.hist(diluted_X, bins=1000, density=True)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21e602387784176ad684459607b7ae3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='zero_dilute_factor', max=1.0, min=0.01, step=0.01), â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Predict on diluted data, optionally dilute 0 class as well.\n",
    "\n",
    "def apply_clf_correction(non_corrected_clf, correction_method, y, diluted_X, diluted_y):\n",
    "    corrected_clf = clone(non_corrected_clf)\n",
    "    #Apply correction\n",
    "    tau = sum(y)/len(y)\n",
    "    y_bar =  sum(diluted_y)/len(diluted_y)\n",
    "    if correction_method == \"prior\":\n",
    "        corrected_intercept = non_corrected_clf.intercept_ - np.log( (1-tau)/tau*y_bar/(1-y_bar)    )\n",
    "        corrected_clf.intercept_ = corrected_intercept\n",
    "    elif correction_method == \"weighting\":\n",
    "        w1 = tau/y_bar\n",
    "        w0 = (1-tau)/(1-y_bar)\n",
    "        corrected_clf = LogisticRegressionCV(cv=5, random_state=0, class_weight={0:w0, 1:w1}).fit(diluted_X, diluted_y)\n",
    "#         y_hat_D = diluted_clf_weighing.predict(X_test_D)\n",
    "#         print(classification_report(y_hat_D, y_test_D ))\n",
    "#         probs_D = diluted_clf_weighing.predict_proba(X_test_D)\n",
    "#         print(\"Theta0_D: {}, theta1_D: {}\".format(diluted_clf_weighing.intercept_, diluted_clf_weighing.coef_))\n",
    "#         ax1.scatter(X_test_D, probs_D[:,1])\n",
    "#         y_hat_all_weighing = diluted_clf_weighing.predict(X_test)\n",
    "#         print(classification_report(y_hat_all_weighing, y_test))\n",
    "#         probs_all_weighing = diluted_clf_weighing.predict_proba(X_test)\n",
    "#         ax1.scatter(X_test, probs_all_weighing[:,1])\n",
    "\n",
    "    return corrected_clf\n",
    "        \n",
    "@interact_manual\n",
    "def dilute_zeros_and_predict( zero_dilute_factor=widgets.FloatSlider(min=0.01,max=1,step=0.01,value=1), \n",
    "                           correction_method = ['none', 'prior', 'weighting', 'gev']):\n",
    "    diluted_X = data_container.diluted_X\n",
    "    diluted_y = data_container.diluted_y\n",
    "    diluted_X_zeros = diluted_X[diluted_y == 0]\n",
    "    diluted_X_ones = diluted_X[diluted_y == 1]\n",
    "\n",
    "    #Dilute the 0's class\n",
    "   \n",
    "    diluted_X, diluted_y = dilute_class(diluted_X, diluted_y, 0, zero_dilute_factor)\n",
    "    diluted_X_zeros = diluted_X[diluted_y == 0]\n",
    "    diluted_X_ones = diluted_X[diluted_y == 1]\n",
    "    y = data_container.y\n",
    "    diluted_y = data_container.diluted_y\n",
    "    tau = sum(y)/len(y)\n",
    "    y_bar =  sum(diluted_y)/len(diluted_y)\n",
    "    #Predict\n",
    "    display(HTML(f'<h3>Using a dataset of size {len(diluted_y)}, {len(diluted_X_zeros)} of which are 0,\\\n",
    "    and {len(diluted_X_ones)} are 1 <h3>'))\n",
    "    #Not sure I need this - the test set is the original one.\n",
    "#     X_train_D, X_test_D, y_train_D, y_test_D = train_test_split(diluted_X, diluted_y, test_size = 0.2) \n",
    "#     print(sum(y_train_D))\n",
    "#     print(sum(y_test_D))\n",
    "    diluted_clf = LogisticRegressionCV(cv=5, random_state=0).fit(diluted_X, diluted_y)\n",
    "    print(\"Before correction: Theta0_D: {}, theta1_D: {}\".format(diluted_clf.intercept_, diluted_clf.coef_))\n",
    "    corrected_clf = apply_clf_correction(diluted_clf, correction_method, y, diluted_X, diluted_y).fit(diluted_X, diluted_y)\n",
    "\n",
    "    #Assess the classifier on the original test data    \n",
    "        \n",
    "    y_hat = corrected_clf.predict(X_test)\n",
    "    print(classification_report(y_hat, y_test ))\n",
    "    probs = corrected_clf.predict_proba(X_test)\n",
    "    data_container.probs_ax.scatter(X_test, probs[:,1], label=f\"0_{zero_dilute_factor}_1_{'tbd'}_{correction_method}\")\n",
    "    data_container.probs_ax.legend()\n",
    "    print(\"Theta0_D: {}, theta1_D: {}\".format(corrected_clf.intercept_, corrected_clf.coef_))\n",
    "    print(confusion_matrix(y_test, y_hat, labels=[1,0]))\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "    \n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Histogram(x=diluted_X_zeros.T[0], nbinsx=1000))\n",
    "    fig.add_trace(go.Histogram(x=diluted_X_ones.T[0], nbinsx=1000))\n",
    "    fig.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prior correction\n",
    "y = data_container.y\n",
    "diluted_y = data_container.diluted_y\n",
    "tau = sum(y)/len(y)\n",
    "y_bar =  sum(diluted_y)/len(diluted_y)\n",
    "print(y_bar)\n",
    "corrected_intercept = diluted_clf.intercept_ - np.log( (1-tau)/tau*y_bar/(1-y_bar)    )\n",
    "diluted_clf.intercept_ = corrected_intercept\n",
    "y_hat_D_corrected = diluted_clf.predict(X_test_D)\n",
    "print(classification_report(y_hat_D_corrected, y_test_D ))\n",
    "probs_D_corrected = diluted_clf.predict_proba(X_test_D)\n",
    "ax1.scatter(X_test_D, probs_D_corrected[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 7\n",
    "print(\"x is: {x}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
