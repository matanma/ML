{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "from pandas_summary import DataFrameSummary\n",
    "import pandas_profiling as pp\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.debugger import set_trace\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import iplot, init_notebook_mode\n",
    "init_notebook_mode(connected=True)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "import xgboost as xgb\n",
    "%matplotlib inline\n",
    "from IPython.core.debugger import set_trace #!!TODO: remove this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse\n",
    "train_set_df = pd.read_csv(\"train_set.csv\", parse_dates = ['timestamp'], date_parser = parse )\n",
    "test_set_df = pd.read_csv(\"test_set.csv\", parse_dates = ['timestamp'], date_parser = parse )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_raw = train_set_df.label\n",
    "train_set_grouped_by_patients = train_set_df.groupby('patient_id')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initial examination of the raw data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = DataFrameSummary(train_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp.ProfileReport(train_set_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The distribution of labels over the raw data is approx: 68% - class 0, 20% - class 1, and 12% - class 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tmp = plt.hist(y_train_raw, bins =  [0,1,2,3] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp[0]/sum(tmp[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The labels are attributes of patients, not of specific samples (all patient's samples have the same label )** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_0 = y_train_raw==0\n",
    "inds_1 = y_train_raw==1\n",
    "inds_2 = y_train_raw==2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiends_0_set = set(train_set_df[inds_0]['patient_id'])\n",
    "patiends_1_set = set(train_set_df[inds_1]['patient_id'])\n",
    "patiends_2_set = set(train_set_df[inds_2]['patient_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiends_0_set.intersection(patiends_1_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiends_0_set.intersection(patiends_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patiends_1_set.intersection(patiends_2_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Each patient's data consists of 3 time series. The number of samples in these series across the patients varies between 1 (single sample) and nearly 100**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_samples_sizes = [len(pdf[1]) for pdf in train_set_grouped_by_patients]\n",
    "plt.hist(train_set_samples_sizes, bins = np.arange(0,100));\n",
    "plt.title(\"Train set - #samples per patient\");\n",
    "plt.xlabel(\"#samples\");\n",
    "plt.ylabel(\"#patients\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The test set has similar distribution, which means, in particular, that we'll need to predict labels of series consisting of a single time sample**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_samples_sizes = [len(pdf[1]) for pdf in test_set_df.groupby('patient_id')]\n",
    "plt.hist(test_set_samples_sizes, bins = np.arange(0,100));\n",
    "plt.title(\"Test set - #samples per patient\");\n",
    "plt.xlabel(\"#samples\");\n",
    "plt.ylabel(\"#patients\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Since the timedelta between each sample is 50ms, the corresponding series durations vary between 0 sec (single sample) to nearly 5 sec (100 samples)** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_samples_durations = [(pdf[1]['timestamp'].iloc[-1] - pdf[1]['timestamp'].iloc[0]).total_seconds() for pdf in train_set_grouped_by_patients]\n",
    "plt.hist(train_set_samples_durations, density=True, bins = np.arange(0, 5, 0.1));\n",
    "plt.title(\"Patients timeseries duration (seconds) \");\n",
    "plt.xlabel(\"series duration\");\n",
    "plt.ylabel(\"density\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Some series are inconsistent in terms of their sizes and durations. Below we see some series with 5 samples (corresponding to 0.2 sec), whose duration is less than 0.2 sec** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(train_set_samples_durations)[np.array(train_set_samples_sizes)==5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's find the one with duration 0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.argmax((np.array(train_set_samples_sizes)==5) & (np.array(train_set_samples_durations) < 0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_grouped_by_patients.get_group(18186)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Seems that the samples behave properly (they are not constant), so it seems like a bug in the timestamps registration. We can either remove such samples as outliers or fix their timestamps based on their number of samples**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Here's another example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_grouped_by_patients.get_group(np.argmax((np.array(train_set_samples_sizes)==5) & (np.array(train_set_samples_durations) == 0.1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_inconsistent_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## TimeSeries - acquaintance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the class is a property of the patient, let's examine the per-patient classes. The classes proportions remain the same as when counting the raw samples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients_classes_df = train_set_grouped_by_patients.nth(0)['label']\n",
    "print(f\"there are {len(patients_classes_df)} patients altogether\")\n",
    "patients_classes_df.hist(bins=[0,1,2,3], density=True);\n",
    "y_per_patient = patients_classes_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot a patient timeseries, optionally with the regressed approximations superimposed (this comes later on)\n",
    "def plot_patient_lines(patient_id, extracted_features = None, plot_ax = None):\n",
    "    if plot_ax is None:\n",
    "        fig_p, ax_p = plt.subplots()\n",
    "    else:\n",
    "        ax_p = plot_ax\n",
    "    \n",
    "    curr_patient_df = train_set_grouped_by_patients.get_group(patient_id)\n",
    "    first_timestamp = curr_patient_df['timestamp'].iloc[0]\n",
    "    curr_patient_df.index = list(map(lambda ts : (ts -first_timestamp).total_seconds()*1000, curr_patient_df['timestamp']))\n",
    "    curr_patient_df[['measurement_x', 'measurement_y', 'measurement_z']].plot(ax=ax_p)\n",
    "    if extracted_features is not None:\n",
    "        coefs = extracted_features.reshape(3,3).T\n",
    "        x_regr = curr_patient_df.index.values\n",
    "        x_mat = np.array([np.ones(len(x_regr)), x_regr, x_regr*x_regr ]).T\n",
    "        curr_patient_df_approx = pd.DataFrame( x_mat.dot(coefs), \n",
    "                                              columns = ['measurement_x_regr', 'measurement_y_regr', 'measurement_z_regr'], \n",
    "                                                index = curr_patient_df.index\n",
    "                                             )\n",
    "        curr_patient_df_approx[['measurement_x_regr', 'measurement_y_regr', 'measurement_z_regr']].plot(ax=ax_p, style='--')\n",
    "    ax_p.set_title(f\"Patient {patient_id} timeseries\")\n",
    "    ax_p.set_xlabel(\"time from first timestamp (ms)\")\n",
    "    return len(curr_patient_df), ax_p\n",
    "\n",
    "#Choose n_patient random patients of class patient_class\n",
    "def choose_rand_patients( n_patients, patient_class ):\n",
    "    if patient_class not in [0,1,2]:\n",
    "        raise Exception(\"Specified patient_class is not in existing classes set: [0,1,2]\")\n",
    "    patient_class_inds = y_per_patient==patient_class\n",
    "    num_class_patients = sum(patient_class_inds)\n",
    "    if n_patients > num_class_patients:\n",
    "        raise Exception(\"Specified num samples {} exceeds the number of patients of requested class {}\".format(n_patients, patient_class))\n",
    "    selected_class_inds = random.sample(range(0, num_class_patients), n_patients)\n",
    "    selected_patients = patients_classes_df[patient_class_inds].index[selected_class_inds]\n",
    "    return selected_patients.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's view some timeseries of each of the classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "patients_ids = choose_rand_patients(1,1)\n",
    "\n",
    "plot_patient_lines(patients_ids[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Typical and less typical classes timeseries**\n",
    "\n",
    "Based on sproradic visual inspection of the timelines. Left images are the more typical, right ones seems less typical to each class.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_figsize = plt.rcParams['figure.figsize'] \n",
    "plt.rcParams['figure.figsize'] = [12, 3]\n",
    "fig_0, (ax_0_typical, ax_0_non_typical) = plt.subplots(1,2)\n",
    "plot_patient_lines(20072, plot_ax=ax_0_typical)\n",
    "plot_patient_lines(15179, plot_ax=ax_0_non_typical)\n",
    "fig_0.suptitle(\"Class 0 timeline - typical and less typical \\n\")\n",
    "plt.tight_layout()\n",
    "\n",
    "fig_1, (ax_1_typical, ax_1_non_typical) = plt.subplots(1,2)\n",
    "plot_patient_lines(9400, plot_ax=ax_1_typical)\n",
    "plot_patient_lines(13166, plot_ax=ax_1_non_typical)\n",
    "fig_1.suptitle(\"Class 1 timeline - typical and less typical \\n\")\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "fig_2, (ax_2_typical, ax_2_non_typical) = plt.subplots(1,2)\n",
    "fig_2.suptitle(\"Class 2 timeline - typical and less typical \\n\")\n",
    "plot_patient_lines(8345, plot_ax=ax_2_typical)\n",
    "plot_patient_lines(3520, plot_ax=ax_2_non_typical) \n",
    "plt.tight_layout()\n",
    "plt.rcParams['figure.figsize']  = curr_figsize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " curr_figsize "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Intermediate summary**\n",
    "\n",
    "- Each patient is characterized by his/her 3 timeseries.  \n",
    "- Visual inspection indicates that each class has a typical footprint in terms of its signals and their mutual configuration.\n",
    "- A reasonable direction would be to represent each signal as a 1st or 2nd order polynomial, and use the coefficient as the features set for each patient.\n",
    "- We can possibly add more features - e.g. whether or not signals intersect (typical to class 2), the average distance between signals (typically the y and z signals in class 1 are close)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Possible additional schemes: whether or not the x and y signals interserct. \n",
    "extraction_schemes = ['parabola']\n",
    "\n",
    "def extract_signals_params(signals_df, extraction_scheme):\n",
    "   \n",
    "    timestamps = signals_df.loc[:, 'timestamp']\n",
    "   \n",
    "    first_timestamp =  timestamps.iloc[0]\n",
    "    x = np.array(list(map(lambda ts : (ts -first_timestamp).total_seconds()*1000, timestamps)))\n",
    "    x = np.array([x, x*x]).T #When the extraction_schemt is 'parabole', actually.\n",
    "    sigs =  signals_df.loc[:, ['measurement_x', 'measurement_y', 'measurement_z']].values\n",
    "    #Regress each signal to a 2nd order polynomial\n",
    "    reg = LinearRegression().fit(x, sigs )\n",
    "    #Add the initial value of each signal, and flatten to a single list.\n",
    "    #Explicitly adding the intial value is redundant, since x starts at 0, hence the intercept is just this initial value\n",
    "    return list(np.concatenate((np.array([reg.intercept_]).T, reg.coef_), axis=1).reshape(1,-1)[0])\n",
    "    \n",
    "    \n",
    "def extract_single_patient_features( patient_df, extraction_scheme ):\n",
    "    patient_id = patient_df['patient_id'].iloc[0]\n",
    "    patient_features = []\n",
    "    curr_line_params = extract_signals_params(patient_df, extraction_scheme)\n",
    "    patient_features += curr_line_params\n",
    "    return patient_features\n",
    "        \n",
    "    \n",
    "def extract_features(in_df, extraction_scheme='parabola'):\n",
    "    #TODO: input sanity checks\n",
    "    X = []\n",
    "    y = []\n",
    "    for _,patient_df in in_df.groupby('patient_id'):\n",
    "        extracted_features = extract_single_patient_features( patient_df, extraction_scheme )\n",
    "        X.append(extracted_features )\n",
    "        if 'label' in patient_df:\n",
    "            y.append(patient_df['label'].iloc[0])\n",
    "    features_names = ['meas_{}_a{}'.format(i,j) for i in ['x', 'y', 'z'] for j in range(3)]\n",
    "    return np.array(X), np.array(y), features_names\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y features_names = extract_features(train_set_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check how well this model encodes the timeseries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_patient_lines(8345, X[8345,:]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot $X|y$, just to get a feeling of how well the features are seperable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_0 = X[ y==0, :]\n",
    "x_1 = X[ y==1, :]\n",
    "x_2 = X[ y==2, :]\n",
    "# len(x_0)\n",
    "fig_x_given_y, ax_x_given_y = plt.subplots()\n",
    "bins_f8 = np.arange(-0.0000001, 0.00000001, 0.000000001)\n",
    "bins_f0 = np.arange(0, 1.5, 0.01)\n",
    "bins_f2 = np.arange(-0.00000004, 0.00000004, 0.000000001)\n",
    "bins_f3 = np.arange(-0.2, 0.6, 0.01)\n",
    "ax_x_given_y.hist(x_0[:,0], bins=bins_f0);\n",
    "ax_x_given_y.hist(x_1[:,0], bins=bins_f0);\n",
    "ax_x_given_y.hist(x_2[:,0], bins=bins_f0);\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3d visualization (3 same order coefficients of the timeseries) indicate that classes 0, 1 are more seperable than class 2.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "i=2\n",
    "j=5\n",
    "k=8\n",
    "\n",
    "def plot_3d_features(i, j, k, title):\n",
    "    fig = go.Figure(data=[go.Scatter3d(x= x_0[:,i], y=x_0[:,j], z=x_0[:,k],\n",
    "                                       mode='markers', name='class 0', \n",
    "                                       marker=dict(\n",
    "                                        size=2,\n",
    "                                        opacity=0.6\n",
    "                                    ))])\n",
    "    fig.add_trace( go.Scatter3d(x= x_1[:,i], y=x_1[:,j], z=x_1[:,k],\n",
    "                                       mode='markers', name='class 1', \n",
    "                                       marker=dict(\n",
    "                                        size=2,\n",
    "                                        opacity=0.6\n",
    "                                    )))\n",
    "\n",
    "    fig.add_trace( go.Scatter3d(x= x_2[:,i], y=x_2[:,j], z=x_2[:,k],\n",
    "                                       mode='markers', name='class 2', \n",
    "                                       marker=dict(\n",
    "                                        size=2,\n",
    "                                        opacity=0.6\n",
    "                                    )))\n",
    "    fig.update_layout(\n",
    "        title={\n",
    "            'text': title,\n",
    "            'y':0.9,\n",
    "            'x':0.5,\n",
    "            'xanchor': 'center',\n",
    "            'yanchor': 'top'})\n",
    "    fig.show()\n",
    "\n",
    "plot_3d_features(0, 3, 6,  \"3 classes ts 0nd order coefficient\")\n",
    "plot_3d_features(2, 5, 8,  \"3 classes ts 2nd order coefficient\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, inds_train, inds_test = train_test_split(X, y, np.arange(len(y)), test_size = 0.2)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes proportions in train set: 0:0.6857615249951371, 1:0.24202489787978992, 2:0.07221357712507294\n"
     ]
    }
   ],
   "source": [
    "#Verify the classes proportions remain.\n",
    "print(\"Classes proportions in train set: 0:{}, 1:{}, 2:{}\".format((y_train == 0).sum()/len(y_train), \n",
    "                                                                  (y_train == 1).sum()/len(y_train), \n",
    "                                                                  (y_train == 2).sum()/len(y_train)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Find optimal meta parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierContainer:\n",
    "    \n",
    "    def __init__(self, clf, long_params_list, short_params_list):\n",
    "        self.clf = clf\n",
    "        self.long_params_list = long_params_list\n",
    "        self.short_params_list = short_params_list\n",
    "        \n",
    "    \n",
    "classifiers_dict = {\n",
    "    'svm': ClassifierContainer(SVC(),\n",
    "                    [{'kernel': ['rbf'], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30],\n",
    "                     'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 700, 800, 1000, 1200, 1500]},\n",
    "                    {'kernel': ['linear'], 'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}\n",
    "                    ], \n",
    "                    [{'kernel': ['rbf'], 'gamma': [  1],\n",
    "                     'C': [300, 500, 1000, 1500]}\n",
    "                    ]\n",
    "            ), \n",
    "                            \n",
    "    'random_forest' : ClassifierContainer(RandomForestClassifier(), \n",
    "                           [{ 'n_estimators' : [100, 200, 500, 1000, 1200, 1500],\n",
    "                              'max_depth': [ 10, 20, 30, 40, 50, 60, 100], \n",
    "                              'class_weight' :['balanced'] }\n",
    "                           ], \n",
    "                            [{ 'n_estimators' : [ 1000],\n",
    "                              'max_depth': [ 30], \n",
    "                              'class_weight' :['balanced'] }\n",
    "                           ]\n",
    "                    ),\n",
    "    \n",
    "    'xgboost' : ClassifierContainer( xgb.XGBClassifier(), \n",
    "                           [{ 'reg_lambda' : [0.1, 0.3, 1, 3, 10, 30, 100, 300],\n",
    "                             'gamma' : [0.001, 0.003, 0.1, 0.3, 1, 3, 10, 30, 100, 300],\n",
    "                              'max_depth': [ 10, 20, 30, 40, 50, 60, 100], \n",
    "                               }\n",
    "                           ], \n",
    "                             [{ 'reg_lambda' : [ 1],\n",
    "                             'gamma' : [ 100],\n",
    "                              'max_depth': [ 30], \n",
    "                               }\n",
    "                           ]\n",
    "                    )\n",
    "            \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_optimal_meta_parameters(train_x, train_y, classifier, tuned_parameters_dict, score='f1'):\n",
    "    \n",
    "    scores = [score]\n",
    "    #This one takes quite some time to complete...\n",
    "    for score in scores:\n",
    "        print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "        print()\n",
    "\n",
    "        clf = GridSearchCV(\n",
    "           classifier, tuned_parameters_dict, scoring='%s_macro' % score\n",
    "        )\n",
    "        clf.fit(train_x, train_y)\n",
    "\n",
    "        print(\"Best parameters set found on development set:\")\n",
    "        print()\n",
    "        print(clf.best_params_)\n",
    "        print()\n",
    "        print(\"Grid scores on development set:\")\n",
    "        print()\n",
    "        means = clf.cv_results_['mean_test_score']\n",
    "        stds = clf.cv_results_['std_test_score']\n",
    "        for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "            print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "                  % (mean, std * 2, params))\n",
    "        print()\n",
    "\n",
    "    return clf.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ############## Tuning meta parameters for classifier svm ########### \n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n",
      "Best parameters set found on development set:\n",
      "\n",
      "{'C': 700, 'gamma': 1, 'kernel': 'rbf'}\n",
      "\n",
      "Grid scores on development set:\n",
      "\n",
      "0.543 (+/-0.007) for {'C': 0.01, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.642 (+/-0.016) for {'C': 0.01, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.680 (+/-0.019) for {'C': 0.01, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.575 (+/-0.002) for {'C': 0.01, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.541 (+/-0.012) for {'C': 0.01, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.01, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.01, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.01, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.737 (+/-0.023) for {'C': 0.03, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.808 (+/-0.020) for {'C': 0.03, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.830 (+/-0.016) for {'C': 0.03, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.799 (+/-0.011) for {'C': 0.03, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.583 (+/-0.002) for {'C': 0.03, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.382 (+/-0.015) for {'C': 0.03, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.03, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.03, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.824 (+/-0.015) for {'C': 0.1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.852 (+/-0.015) for {'C': 0.1, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.865 (+/-0.015) for {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.868 (+/-0.015) for {'C': 0.1, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.809 (+/-0.009) for {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.592 (+/-0.004) for {'C': 0.1, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.293 (+/-0.007) for {'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.271 (+/-0.000) for {'C': 0.1, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.851 (+/-0.016) for {'C': 0.3, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.866 (+/-0.013) for {'C': 0.3, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.880 (+/-0.017) for {'C': 0.3, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.893 (+/-0.015) for {'C': 0.3, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.904 (+/-0.022) for {'C': 0.3, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.868 (+/-0.012) for {'C': 0.3, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.685 (+/-0.014) for {'C': 0.3, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.475 (+/-0.016) for {'C': 0.3, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.865 (+/-0.014) for {'C': 1, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.875 (+/-0.012) for {'C': 1, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.895 (+/-0.009) for {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.910 (+/-0.010) for {'C': 1, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.935 (+/-0.013) for {'C': 1, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.952 (+/-0.007) for {'C': 1, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.950 (+/-0.009) for {'C': 1, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.909 (+/-0.010) for {'C': 1, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.870 (+/-0.018) for {'C': 3, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.886 (+/-0.010) for {'C': 3, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.911 (+/-0.012) for {'C': 3, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.937 (+/-0.012) for {'C': 3, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.958 (+/-0.006) for {'C': 3, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.967 (+/-0.003) for {'C': 3, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.955 (+/-0.009) for {'C': 3, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 3, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.878 (+/-0.013) for {'C': 10, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.898 (+/-0.013) for {'C': 10, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.934 (+/-0.010) for {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.958 (+/-0.005) for {'C': 10, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.971 (+/-0.006) for {'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.974 (+/-0.003) for {'C': 10, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 10, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.886 (+/-0.011) for {'C': 30, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.916 (+/-0.005) for {'C': 30, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.945 (+/-0.007) for {'C': 30, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.964 (+/-0.005) for {'C': 30, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.978 (+/-0.006) for {'C': 30, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 30, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 30, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 30, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.898 (+/-0.012) for {'C': 100, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.933 (+/-0.014) for {'C': 100, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.959 (+/-0.006) for {'C': 100, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.969 (+/-0.008) for {'C': 100, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.983 (+/-0.004) for {'C': 100, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 100, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 100, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 100, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.917 (+/-0.009) for {'C': 300, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.941 (+/-0.011) for {'C': 300, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.965 (+/-0.005) for {'C': 300, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.973 (+/-0.010) for {'C': 300, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 300, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 300, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 300, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 300, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.931 (+/-0.013) for {'C': 700, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.948 (+/-0.006) for {'C': 700, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.008) for {'C': 700, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.977 (+/-0.008) for {'C': 700, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 700, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 700, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 700, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 700, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.932 (+/-0.011) for {'C': 800, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.949 (+/-0.006) for {'C': 800, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.008) for {'C': 800, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.978 (+/-0.007) for {'C': 800, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 800, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 800, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 800, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 800, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.934 (+/-0.011) for {'C': 1000, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.951 (+/-0.005) for {'C': 1000, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.966 (+/-0.007) for {'C': 1000, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.979 (+/-0.008) for {'C': 1000, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 1000, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 1000, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 1000, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 1000, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.935 (+/-0.011) for {'C': 1200, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.952 (+/-0.005) for {'C': 1200, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.967 (+/-0.007) for {'C': 1200, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.980 (+/-0.007) for {'C': 1200, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 1200, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 1200, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 1200, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 1200, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.936 (+/-0.011) for {'C': 1500, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.954 (+/-0.005) for {'C': 1500, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.967 (+/-0.006) for {'C': 1500, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.980 (+/-0.008) for {'C': 1500, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.985 (+/-0.004) for {'C': 1500, 'gamma': 1, 'kernel': 'rbf'}\n",
      "0.976 (+/-0.003) for {'C': 1500, 'gamma': 3, 'kernel': 'rbf'}\n",
      "0.956 (+/-0.010) for {'C': 1500, 'gamma': 10, 'kernel': 'rbf'}\n",
      "0.930 (+/-0.005) for {'C': 1500, 'gamma': 30, 'kernel': 'rbf'}\n",
      "0.838 (+/-0.019) for {'C': 0.01, 'kernel': 'linear'}\n",
      "0.839 (+/-0.018) for {'C': 0.03, 'kernel': 'linear'}\n",
      "0.842 (+/-0.019) for {'C': 0.1, 'kernel': 'linear'}\n",
      "0.843 (+/-0.021) for {'C': 0.3, 'kernel': 'linear'}\n",
      "0.842 (+/-0.021) for {'C': 1, 'kernel': 'linear'}\n",
      "0.842 (+/-0.021) for {'C': 3, 'kernel': 'linear'}\n",
      "0.842 (+/-0.021) for {'C': 10, 'kernel': 'linear'}\n",
      "0.842 (+/-0.021) for {'C': 30, 'kernel': 'linear'}\n",
      "\n",
      "\n",
      " ############## Tuning meta parameters for classifier random_forest ########### \n",
      "\n",
      "# Tuning hyper-parameters for f1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tune_long_list = True\n",
    "tuned_classifiers = {}\n",
    "for clfname in c lassifiers_dict:\n",
    "    print( \"\\n ############## Tuning meta parameters for classifier {} ########### \\n\".format(clfname))\n",
    "    clf_params_to_tune = classifiers_dict[clfname]\n",
    "    curr_best_estimator = find_optimal_meta_parameters(X_train_scaled, y_train, clf_params_to_tune.clf, \n",
    "                                 clf_params_to_tune.long_params_list if tune_long_list else clf_params_to_tune.short_params_list,\n",
    "                                 score='f1')\n",
    "    tuned_classifiers[clfname] = curr_best_estimator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_features_importances(importances):\n",
    "    plt.figure(figsize=(12, 3))\n",
    "    plt.title(\"Feature importances\")\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    plt.bar(range(len(importances)), importances[indices],\n",
    "            color=\"r\",align=\"center\")\n",
    "    plt.xticks(range(len(importances)), np.array(features_names)[indices])\n",
    "    plt.xlim([-1, len(importances)])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "################# cassification report for classifier svm ################\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3511\n",
      "           1       1.00      1.00      1.00      1237\n",
      "           2       1.00      1.00      1.00       394\n",
      "\n",
      "    accuracy                           1.00      5142\n",
      "   macro avg       1.00      1.00      1.00      5142\n",
      "weighted avg       1.00      1.00      1.00      5142\n",
      "\n",
      "\n",
      " Confusion matrix (Wikipedia format):\n",
      "\n",
      "[[3511    0    0]\n",
      " [   0 1237    0]\n",
      " [   0    0  394]]\n",
      "\n",
      " Confusion matrix (sklearn (transposed) format):\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't produce feature importance for classifier svm\n",
      "\n",
      "##################################################################################\n",
      "\n",
      "\n",
      "\n",
      "################# cassification report for classifier random_forest ################\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3511\n",
      "           1       1.00      1.00      1.00      1237\n",
      "           2       1.00      1.00      1.00       394\n",
      "\n",
      "    accuracy                           1.00      5142\n",
      "   macro avg       1.00      1.00      1.00      5142\n",
      "weighted avg       1.00      1.00      1.00      5142\n",
      "\n",
      "\n",
      " Confusion matrix (Wikipedia format):\n",
      "\n",
      "[[3507    4    0]\n",
      " [   4 1233    0]\n",
      " [   0    0  394]]\n",
      "\n",
      " Confusion matrix (sklearn (transposed) format):\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################################\n",
      "\n",
      "\n",
      "\n",
      "################# cassification report for classifier xgboost ################\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      3511\n",
      "           1       0.99      0.99      0.99      1237\n",
      "           2       0.99      1.00      1.00       394\n",
      "\n",
      "    accuracy                           1.00      5142\n",
      "   macro avg       0.99      1.00      0.99      5142\n",
      "weighted avg       1.00      1.00      1.00      5142\n",
      "\n",
      "\n",
      " Confusion matrix (Wikipedia format):\n",
      "\n",
      "[[3502   10    0]\n",
      " [   9 1225    1]\n",
      " [   0    2  393]]\n",
      "\n",
      " Confusion matrix (sklearn (transposed) format):\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x216 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "##################################################################################\n",
      "\n",
      "The classifier with the maximal minimal f1 score is svm\n"
     ]
    }
   ],
   "source": [
    "#Summarize the performance of each of the tuned classifiers, and find the one with max-min F1 score.\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "min_f1 = {}\n",
    "curr_figsize = plt.rcParams['figure.figsize']\n",
    "for clfname in tuned_classifiers:\n",
    "    print()\n",
    "    print( \"\\n################# cassification report for classifier {} ################\\n\".format(clfname))\n",
    "    clf = best_classifiers[clfname]\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print( classification_report(y_true, y_pred) )\n",
    "    print(\"\\n Confusion matrix (Wikipedia format):\\n\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T) \n",
    "    print(\"\\n Confusion matrix (sklearn (transposed) format):\\n\")\n",
    "    plot_confusion_matrix(clf, X_test_scaled, y_true, display_labels=['class 0', 'class 1', 'class 2'], values_format='.0f')\n",
    "    plt.show()\n",
    "    if hasattr(clf, 'feature_importances_'):\n",
    "        plot_features_importances( clf.feature_importances_)\n",
    "    else:\n",
    "        print(\"Can't produce feature importance for classifier {}\".format(clfname))\n",
    "        \n",
    "    min_f1[clfname] = np.min(f1_score(y_true, y_pred, average=None))\n",
    "    print(\"\\n##################################################################################\\n\")\n",
    "    \n",
    "sorted_clfnames_by_scores = [k for k, v in sorted(min_f1.items(), key=lambda item: item[1])]\n",
    "best_classifier = tuned_classifiers[sorted_clfnames_by_scores[-1]]\n",
    "print(\"The classifier with the maximal minimal f1 score is {}\".format(sorted_clfnames_by_scores[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'svm': 1.0,\n",
       " 'random_forest': 0.9987859166329423,\n",
       " 'xgboost': 0.9983818770226538}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Use the entire training set to train the submission classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_for_submission,_  = extract_features(test_set_df)\n",
    "scaler_submission = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler_submission.transform(X)\n",
    "X_test_for_submission_scaled = scaler_submission.transform(X_test_for_submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_long_list = True\n",
    "tuned_classifiers_submission = {}\n",
    "for clfname in classifiers_dict:\n",
    "    print( \"\\n ############## Tuning meta parameters for classifier {} \\n\".format(clfname))\n",
    "    clf_params_to_tune = classifiers_dict[clfname]\n",
    "    curr_best_estimator = find_optimal_meta_parameters(X_scaled, y, clf_params_to_tune.clf, \n",
    "                                 clf_params_to_tune.long_params_list if tune_long_list else clf_params_to_tune.short_params_list,\n",
    "                                 score='f1')\n",
    "    tuned_classifiers[clfname] = curr_best_estimator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now apply on provided test set.\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "res_df = pd.DataFrame( { 'label' : y_test_hat, 'patient_id' : test_set_df.groupby('patient_id').nth(0).index.values})\n",
    "res_df.to_csv(\"clew_assignment_submission_matan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = sklearn.metrics.f1_score(y_true, y_pred, average=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99415371, 0.97972425, 0.98881988])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30],\n",
    "                     'C': [1, 30, 100 ,300, 500, 800, 1000, 1500]}\n",
    "                   ]\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(\n",
    "       SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_scaled, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "# Now apply on provided test set.\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "res_df = pd.DataFrame( { 'label' : y_test_hat, 'patient_id' : test_set_df.groupby('patient_id').nth(0).index.values})\n",
    "res_df.to_csv(\"clew_assignment_submission_matan.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM with gaussian kernel**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SVM ####################\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.debugger import set_trace\n",
    "# SVM with gaussian kernel\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30],\n",
    "                     'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30, 100, 300, 700, 800, 1000, 1500]},\n",
    "                    {'kernel': ['linear'], 'C': [0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]}]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "#This one takes quite some time to complete...\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### SVM ####################\n",
    "from sklearn.svm import SVC\n",
    "from IPython.core.debugger import set_trace\n",
    "# SVM with gaussian kernel\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [  1],\n",
    "                     'C': [300, 500, 800, 1000, 1500]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(\"Confusion matrix:\")\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Where have we missed?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ i for i,val in enumerate((y_true == 2) & (y_pred == 1)) if val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inds_test[1194]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test[240,:]\n",
    "plot_patient_lines(24602, X[24602,:] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{  \n",
    "                       'n_estimators' : [100, 200, 500, 1000],\n",
    "                        'max_depth': [ 10, 20, 30, 40, 50, 60], \n",
    "                       'class_weight' :['balanced']\n",
    "                    }\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       RandomForestClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{ 'reg_lambda' : [0.1, 0.3, 1, 3, 10, 30, 100, 300],\n",
    "                             'reg_alpha ' : [0.1, 0.3, 1, 3, 10, 30, 100, 300],\n",
    "                              'max_depth': [ 10, 20, 30, 40, 50, 60], \n",
    "                               }\n",
    "                           ]\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       xgb.XGBClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc()\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure()\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=4)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=4)\n",
    "\n",
    "colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## Logistic Regression ########################\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\n",
    "# scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "# X_logit = scaler.transform(X_train)\n",
    "# X_logit_test = scaler.transform(X_test)\n",
    "clf = LogisticRegressionCV(cv=5, max_iter = 1000).fit(X_train_scaled, y_train)\n",
    "y_hat = clf.predict(X_test_scaled)\n",
    "# X_test_predicted_0 = X_test[y_hat==0]\n",
    "# X_test_predicted_1 = X_test[y_hat==1]\n",
    "# plt.scatter(X_test_predicted_0[:,0], X_test_predicted_0[:,1], c='y')\n",
    "# plt.scatter(X_test_predicted_1[:,0], X_test_predicted_1[:,1], c='b')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_hat, labels=[0, 1, 2])\n",
    "print(cnf_matrix.T)\n",
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithms \n",
    "clf_dict = {\"Logistic Regression\":LogisticRegression(penalty='l2', C=1, class_weight='balanced', solver='lbfgs'), # \n",
    "            \"Random Forest\": RandomForestClassifier(n_estimators=55, random_state=6),\n",
    "            \"XGBoost\": xgb.XGBClassifier()#(objective='multi:softmax')#, num_class=num_class\n",
    "           }\n",
    "\n",
    "\n",
    "classifiers = {\n",
    "#     \"LogisiticRegression\": LogisticRegression(),\n",
    "#     \"KNearest\": KNeighborsClassifier(),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "#     \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "# }\n",
    "\n",
    "tuned_parameters = [{  'n_neighbors': [2, 3, 4]}\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       KNeighborsClassifier(), tuned_parameters, scoring='%s_macro' % score, cv=7\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers = {\n",
    "#     \"LogisiticRegression\": LogisticRegression(),\n",
    "#     \"KNearest\": KNeighborsClassifier(),\n",
    "#     \"Support Vector Classifier\": SVC(),\n",
    "#     \"DecisionTreeClassifier\": DecisionTreeClassifier()\n",
    "# }\n",
    "\n",
    "tuned_parameters = [{  'Cs': [0.1, 0.3, 1, 3, 10, 30, 100, 300, 1000, 3000]], \n",
    "                        'class_weight' : [None, 'balanced']\n",
    "                    }\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       LogisticRegression(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{  'max_depth': [ 10, 20, 30, 40, 50, 60], \n",
    "                       'class_weight' :['balanced']\n",
    "                    }\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       DecisionTreeClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "    y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_parameters = [{  'max_depth': [ 4,5, 6, 10, 20, 30, 40, 50, 60], \n",
    "                       'class_weight' :['balanced']\n",
    "                    }\n",
    "                    ]\n",
    "\n",
    "\n",
    "\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(\n",
    "       DecisionTreeClassifier(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_scaled, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    print()\n",
    "#     y_true, y_pred = y_test, clf.predict(X_test_scaled)\n",
    "#     print(classification_report(y_true, y_pred))\n",
    "#     print(confusion_matrix(y_true, y_pred, labels=[0,1,2]).T)\n",
    "#     print()\n",
    "\n",
    "# clf.fit(, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcv = pd.DataFrame(clf.cv_results_)\n",
    "dfcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfcv[[\"split{}_test_score\".format(j) for j in range(7)]].mean(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "# print('Length of X (train): {} | Length of y (train): {}'.format(len(original_Xtrain), len(original_ytrain)))\n",
    "# print('Length of X (test): {} | Length of y (test): {}'.format(len(original_Xtest), len(original_ytest)))\n",
    "\n",
    "# List to append the score and then find the average\n",
    "accuracy_lst = []\n",
    "precision_lst = []\n",
    "recall_lst = []\n",
    "f1_lst = []\n",
    "auc_lst = []\n",
    "\n",
    "# Classifier with optimal parameters\n",
    "# log_reg_sm = grid_log_reg.best_estimator_\n",
    "log_reg_sm = LogisticRegression()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Implementing SMOTE Technique \n",
    "# Cross Validating the right way\n",
    "# Parameters\n",
    "log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000]}\n",
    "rand_log_reg = RandomizedSearchCV(LogisticRegression(), log_reg_params, n_iter=4)\n",
    "sss = StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\n",
    "for train, test in sss.split(X_train_scaled, y_train):\n",
    "    pipeline = imbalanced_make_pipeline(SMOTE(sampling_strategy='minority'), rand_log_reg) # SMOTE happens during Cross Validation not before..\n",
    "    model = pipeline.fit(X_train_scaled[train], y_train[train])\n",
    "    best_est = rand_log_reg.best_estimator_\n",
    "    prediction = best_est.predict(X_train_scaled[test])\n",
    "    \n",
    "    accuracy_lst.append(pipeline.score(X_train_scaled[test], y_train[test]))\n",
    "    precision_lst.append(precision_score(y_train[test], prediction))\n",
    "    recall_lst.append(recall_score(y_train[test], prediction))\n",
    "    f1_lst.append(f1_score(y_train[test], prediction))\n",
    "    auc_lst.append(roc_auc_score(y_train[test], prediction))\n",
    "    \n",
    "print('---' * 45)\n",
    "print('')\n",
    "print(\"accuracy: {}\".format(np.mean(accuracy_lst)))\n",
    "print(\"precision: {}\".format(np.mean(precision_lst)))\n",
    "print(\"recall: {}\".format(np.mean(recall_lst)))\n",
    "print(\"f1: {}\".format(np.mean(f1_lst)))\n",
    "print('---' * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameters by cross-validation\n",
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [0.01, 0.03, 0.1],\n",
    "                     'C': [ 800, 1000]}\n",
    "                   ]\n",
    "scores = ['f1']\n",
    "\n",
    "for score in scores:\n",
    "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
    "    print()\n",
    "    clf = GridSearchCV(\n",
    "       SVC(), tuned_parameters, scoring='%s_macro' % score\n",
    "    )\n",
    "    clf.fit(X_scaled, y)\n",
    "\n",
    "    print(\"Best parameters set found on development set:\")\n",
    "    print()\n",
    "    print(clf.best_params_)\n",
    "    print()\n",
    "    print(\"Grid scores on development set:\")\n",
    "    print()\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "    print()\n",
    "\n",
    "    print(\"Detailed classification report:\")\n",
    "    print()\n",
    "    print(\"The model is trained on the full development set.\")\n",
    "    print(\"The scores are computed on the full evaluation set.\")\n",
    "    \n",
    "# Now apply on provided test set.\n",
    "y_test_hat = clf.predict(X_test_scaled)\n",
    "res_df = pd.DataFrame( { 'label' : y_test_hat, 'patient_id' : test_set_df.groupby('patient_id').nth(0).index.values})\n",
    "res_df.to_csv(\"clew_assignment_submission_matan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat_test_of_submission_clf = clf.best_estimator_.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_hat_test_of_submission_clf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc_partial_train = SVC(C=1000, kernel='rbf', gamma=1)\n",
    "clf_svc_full_train = SVC(C=1000, kernel='rbf', gamma=0.03)\n",
    "scaler = preprocessing.StandardScaler().fit(X)\n",
    "X_scaled = scaler.transform(X)\n",
    "# X_test_raw_scaled = scaler.transform(X_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc_partial_train.fit(X_train_scaled, y_train)\n",
    "y_hat_partial = clf_svc_partial_train.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_partial))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_svc_full_train.fit(X_scaled, y)\n",
    "y_hat_full = clf_svc_full_train.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat_full))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set_df.groupby('patient_id').nth(0).index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame( { 'label' : y_test_hat, 'patient_id' : test_set_df.groupby('patient_id').nth(0).index.values})\n",
    "res_df.to_csv(\"clew_assignment_submission_matan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_binary = y_true\n",
    "y_true_binary[y_true_binary == 1] = 0\n",
    "y_true_binary[y_true_binary == 2] = 1\n",
    "np.unique(y_true_binary)\n",
    "print(np.unique(y_true))\n",
    "y_pred_binary = y_pred\n",
    "y_pred_binary[y_pred_binary == 1] = 0\n",
    "y_pred_binary[y_pred_binary == 2] = 1\n",
    "np.unique(y_pred_binary)\n",
    "all((y_pred_binary==1) == (y_pred == 2))\n",
    "# sklearn.metrics.f1_score(y_true_binary, y_pred_binary) \n",
    "print(classification_report(y_true_binary, y_pred_binary))\n",
    "print(confusion_matrix(y_true_binary, y_pred_binary, labels=[0, 1]).T)\n",
    "print(confusion_matrix(y_true, y_pred, labels=[0, 1,2]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO:\n",
    "* Remove outliers (corrupted ts)\n",
    "* Weigh signals based on their duration (a signal of 4 timestamps is less indicative than a 30 samples one). Additionally - apply classification on only the subset of signals with more than M timestamp and show scores over this set. \n",
    "* More features: do lines intersect? what's the average distane between two lines?\n",
    "* Beautify code: add parameters types, sanity tests and comments, remove debug printouts.\n",
    "\n",
    "* Add ROC\n",
    "* If possible - use these fancy auto analysis pandas tools.\n",
    "\n",
    "Theoretical:\n",
    "* squared v.s. abs regularization\n",
    "* Trees v.s. LR v.s. SVM - which one will be better under which circumstances? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting examples:\n",
    "* 15175, 15176 - two examples of 2 class which are quite different\n",
    "* 15178, 15179 - two examples of 0 class which seem identical, and also typical to type 2 class. More typical 0 ones: 1903\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_fab = [ 0,0,0,0,0,0,0,0, 1,1,1, 1, 2, 2, 2]\n",
    "y_hat_fab = [ 0,0,0,0,0,0,1,2, 1,1,0, 2, 1, 2, 2]\n",
    "print(classification_report(y_true_fab, y_hat_fab, labels=[0,1,2]))\n",
    "print(confusion_matrix(y_true_fab, y_hat_fab).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "6/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
